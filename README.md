# ğŸ¬ Movie ETL Pipeline (TMDB API)

An end-to-end **ETL (Extract â€“ Transform â€“ Load)** data engineering project using the **TMDB API**, **Python**, and **SQLite**.

The pipeline collects movie data from an external API, cleans and normalizes it, loads it into a relational database, and performs analytical queries whose results are also **visualized into charts** for better insight.

---

## ğŸ“Œ Project Overview

This project simulates a real-world data engineering workflow with clear separation of responsibilities across ETL stages.

It demonstrates how to:
- Extract data from a REST API
- Transform raw JSON responses into a clean, structured format
- Load processed data into a relational database
- Analyze stored data using SQL and Python
- Visualize analytical query results into meaningful charts

---

## ğŸ§± Architecture

TMDB API  
â†“  
collect.py â†’ data/raw/  
â†“  
transform.py â†’ data/processed/  
â†“  
load.py â†’ SQLite (movies.db)  
â†“  
analysis.py â†’ SQL-based insights  
â†“  
visualize.py â†’ charts & reports (PNG)

---

## ğŸ› ï¸ Tech Stack

- Python 3
- Requests (API communication)
- SQLite (local relational database)
- SQL (data analysis)
- python-dotenv (environment variables)
- Logging (pipeline observability)
- Matplotlib (data visualization)
- VS Code + SQLite Explorer (database inspection)

---

## ğŸ“‚ Project Structure

```text

movie_etl_api/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ collect.py        # Extract data from TMDB API
â”‚   â”œâ”€â”€ transform.py      # Clean & normalize raw data
â”‚   â”œâ”€â”€ load.py           # Load data into SQLite
â”‚   â”œâ”€â”€ analysis.py       # Query & analyze stored data
â”‚   â””â”€â”€ visualize.py      # Visualize SQL query results
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw API responses (JSON)
â”‚   â””â”€â”€ processed/        # Cleaned movie data
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ movies.db         # SQLite database
â”‚   â”œâ”€â”€ init.sql          # Database schema
â”‚   â””â”€â”€ queries.sql       # Analytical SQL queries
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ top_popular_movies.png
â”‚   â””â”€â”€ top_rated_movies.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                  # API credentials (not committed)
â””â”€â”€ README.md

```
---

## âš™ï¸ Setup Instructions

1. Clone the repository  
2. Create and activate a virtual environment  
3. Install dependencies using: pip install -r requirements.txt  
4. Create a .env file in the project root containing: TMDB_API_KEY=your_api_key_here  

---

## â–¶ï¸ Running the Pipeline

Run each step in order from the project root using the following commands:

python etl/collect.py  
python etl/transform.py  
python etl/load.py  
python etl/analysis.py  
python etl/visualize.py  

If all steps complete successfully, the ETL pipeline has executed end-to-end and produced both data and visual reports.

---

## ğŸ” Data Validation

- Raw data is stored in data/raw/
- Processed data is stored in data/processed/
- Loaded data is stored in database/movies.db
- Tables and records can be inspected via SQLite Explorer
- SQL analysis queries are defined in database/queries.sql
- Visualization outputs are saved in the reports/ directory

---

## ğŸ“Š Example Analyses & Visualizations

- Total number of movies stored
- Top 10 most popular movies (visualized as bar chart)
- Top-rated movies with a minimum vote threshold (visualized as bar chart)

Each visualization is generated directly from the corresponding SQL query results.

---

## âœ… Project Status

The ETL pipeline is complete and fully functional.

Potential future improvements include:
- API pagination and incremental loads
- Workflow orchestration (Airflow / Prefect)
- Data quality checks
- Interactive dashboards
- Containerization with Docker

---

## ğŸ§  Key Takeaway

This project focuses on understanding **data flow and structure**, not memorization.  
Each ETL and analysis step is isolated, testable, and verifiable, closely reflecting real-world data engineering and analytics workflows.

---

## ğŸ‘¤ Author

Built as a hands-on data engineering learning project using real-world tools and workflows.
